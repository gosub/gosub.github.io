#+hugo_base_dir: site/
* site config
** main
#+name: main
#+begin_src toml :tangle site/hugo.toml :noweb yes
  baseURL = 'https://giampaolo.guiducci.it/'
  languageCode = 'en-us'
  title = 'Giampaolo Guiducci'
  theme = 'cactus'
  publishDir = '../docs'
  capitalizeListTitles = false

  [params]
    description = "An empty set, by construction."
    mainSection = "posts"
    mainSections = ["posts"]
    mainSectionTitle = "posts"
    <<socials>>

  <<menu>>

  [markup.goldmark.renderer]
    unsafe = true
#+end_src
*** socials
#+name: socials
#+begin_src toml
[[params.social]]
  name = "email"
  link = "giampaolo.guiducci@gmail.com"

[[params.social]]
  name = "github"
  link = "https://github.com/gosub"

[[params.social]]
  name = "instagram"
  link = "https://instagram.com/sottoforma"
#+end_src
*** menu
#+name:menu
#+begin_src toml
[[menu.main]]
name = "home"
url = "/"
weight = 1

[[menu.main]]
name = "posts"
url = "/posts"
weight = 2

[[menu.main]]
name = "μlog"
url = "/μlog"
weight = 3

[[menu.main]]
name = "tags"
url = "/tags"
weight = 4
#+end_src
** cname
#+name: cname
#+begin_src cname :tangle site/static/CNAME
giampaolo.guiducci.it
#+end_src
* posts
** TODO All the papers cited in Andrej Karpathy's youtube videos :ai:
:PROPERTIES:
:EXPORT_FILE_NAME: 2026-02-09-karpathy-video-papers
:EXPORT_DATE: 2026-02-09T20:51:32+01:00
:END:

https://www.youtube.com/@AndrejKarpathy/videos

#+begin_src sh
yt-dlp --skip-download --write-subs --write-auto-subs --sub-lang en --sub-format ttml --convert-subs srt --output "transcript_%(id)s_%(title)s.%(ext)s" ${URL}
#+end_src

*** The spelled-out intro to neural networks and backpropagation: building micrograd
https://www.youtube.com/watch?v=VMj-3S1tku0

*** The spelled-out intro to language modeling: building makemore
https://www.youtube.com/watch?v=PaCmpygFfXo

*** Building makemore Part 2: MLP
https://www.youtube.com/watch?v=TCH_1BHY58I
**** bengio et al 2003 - A Neural Probabilistic Language Model
https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf

*** Building makemore Part 3: Activations & Gradients, BatchNorm
https://www.youtube.com/watch?v=P6sfmUTpUmc
**** Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification
https://arxiv.org/abs/1502.01852
**** Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
https://arxiv.org/abs/1502.03167

*** Building makemore Part 4: Becoming a Backprop Ninja
https://www.youtube.com/watch?v=q8SA3rM6ckI
**** Reducing the Dimensionality of Data with Neural Networks
https://www.cs.toronto.edu/~hinton/absps/science.pdf
**** Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
https://arxiv.org/abs/1406.5679
**** Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
https://arxiv.org/abs/1502.03167
**** Bessel's Correction
https://mathcenter.oxford.emory.edu/site/math117/besselCorrection/
*** Building makemore Part 5: Building a WaveNet
https://www.youtube.com/watch?v=t3YJ5hKiMQ0
**** WaveNet: A Generative Model for Raw Audio
https://arxiv.org/abs/1609.03499
**** bengio et al 2003 - A Neural Probabilistic Language Model
https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf
*** Let's build GPT: from scratch, in code, spelled out.
https://www.youtube.com/watch?v=kCc8FmEb1nY
**** Attention is All You Need
https://arxiv.org/abs/1706.03762
**** Layer Normalization
https://arxiv.org/abs/1607.06450
**** Dropout: A Simple Way to Prevent Neural Networks from Overfitting
https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf
**** Language Models are Few-Shot Learners
https://arxiv.org/abs/2005.14165
**** Introducing ChatGPT
https://openai.com/index/chatgpt/
*** [1hr Talk] Intro to Large Language Models
https://www.youtube.com/watch?v=zjkBMFhNj_g
**** Llama 2: Open Foundation and Fine-Tuned Chat Models
https://arxiv.org/abs/2307.09288
**** Training language models to follow instructions with human feedback
https://arxiv.org/abs/2203.02155
**** Tree of Thoughts: Deliberate Problem Solving with Large Language Models, Yao et al. 2023
https://arxiv.org/abs/2305.10601
**** Training Compute-Optimal Large Language Models
https://arxiv.org/abs/2203.15556
**** Sparks of Artificial General Intelligence: Early experiments with GPT-4, Bubuck et al. 2023
https://arxiv.org/abs/2303.12712
**** Mastering the game of Go with deep neural networks and tree search
https://www.researchgate.net/publication/292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search
**** Jailbroken: How Does LLM Safety Training Fail?
https://arxiv.org/abs/2307.02483
**** Universal and Transferable Adversarial Attacks on Aligned Language Models
https://arxiv.org/abs/2307.15043
**** Visual Adversarial Examples Jailbreak Aligned Large Language Models
https://arxiv.org/abs/2306.13213
**** Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection
https://arxiv.org/abs/2302.12173
**** Hacking Google Bard - From Prompt Injection to Data Exfiltration
https://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/
**** Poisoning Language Models During Instruction Tuning
https://arxiv.org/abs/2305.00944
**** Poisoning Web-Scale Training Datasets is Practical
https://arxiv.org/abs/2302.10149
**** OWASP Top 10 for LLM Applications
https://owasp.org/www-project-top-10-for-large-language-model-applications/
*** Let's build the GPT Tokenizer
https://www.youtube.com/watch?v=zduSFxRajkE
**** Language Models are Unsupervised Multitask Learners
https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
**** Llama 2: Open Foundation and Fine-Tuned Chat Models
https://arxiv.org/abs/2307.09288
**** A Programmer’s Introduction to Unicode
https://www.reedbeta.com/blog/programmers-intro-to-unicode/
**** MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers
https://arxiv.org/abs/2305.07185
**** Efficient Training of Language Models to Fill in the Middle
https://arxiv.org/abs/2207.14255
**** Learning to Compress Prompts with Gist Tokens
https://arxiv.org/abs/2304.08467
**** Taming Transformers for High-Resolution Image Synthesis
https://arxiv.org/abs/2012.09841
https://compvis.github.io/taming-transformers/
**** Video generation models as world simulators
https://openai.com/index/video-generation-models-as-world-simulators/
**** Integer tokenization is insane
https://www.beren.io/2023-02-04-Integer-tokenization-is-insane/
**** SolidGoldMagikarp (plus, prompt generation)
https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation

*** Let's reproduce GPT-2 (124M)
https://www.youtube.com/watch?v=l8pRSuU81PU
**** Language Models are Unsupervised Multitask Learners
https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
**** Language Models are Few-Shot Learners
https://arxiv.org/abs/2005.14165
**** Attention is All You Need
https://arxiv.org/abs/1706.03762
**** Gaussian Error Linear Units (GELUs)
https://arxiv.org/abs/1606.08415
**** Using the Output Embedding to Improve Language Models
https://arxiv.org/abs/1608.05859
**** NVIDIA A100 Tensor Core GPU Architecture
https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf
**** FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
https://arxiv.org/abs/2205.14135
**** FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning
https://arxiv.org/abs/2307.08691
**** Online normalizer calculation for softmax
https://arxiv.org/abs/1805.02867
**** HellaSwag: Can a Machine Really Finish Your Sentence?
https://arxiv.org/abs/1905.07830
*** Deep Dive into LLMs like ChatGPT
https://www.youtube.com/watch?v=7xTGNNLPyMI
**** Language Models are Unsupervised Multitask Learners
https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
**** The Llama 3 Herd of Models
https://arxiv.org/abs/2407.21783
**** Training language models to follow instructions with human feedback
https://arxiv.org/abs/2203.02155
**** DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning
https://arxiv.org/abs/2501.12948
**** Mastering the Game of Go without Human Knowledge
https://discovery.ucl.ac.uk/id/eprint/10045895/1/agz_unformatted_nature.pdf
**** Fine-Tuning Language Models from Human Preferences
https://arxiv.org/abs/1909.08593
*** How I use LLMs
https://www.youtube.com/watch?v=EWvNQjAaOHw
**** DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning
https://arxiv.org/abs/2501.12948

** The many faces of the XOR operation :xor:programming:
:PROPERTIES:
:EXPORT_FILE_NAME: 2026-01-05-many-faces-of-xor
:EXPORT_DATE: 2026-01-05T18:45:20+01:00
:END:

XOR has always struck me as the odd one among the logical operators; since I
first learned about it, I always felt a strange fascination with it. I think I
was taught about it by my father, who cultivated my interest in computers and
taught me programming when I was 7. I remember that the AND and OR operations
were clear to me, and their use in the logic of a program; on the other hand,
XOR seemed esoteric and not really useful, since I could easily program the same
behavior with a combination of AND and OR.  As I progressed in my programming
journey and learned much more, I became aware of the strangeness and power of
XOR. In this post, I explore the many interpretations of XOR, and why it
deserves a unique appreciation.

*** The Boring Formal Definition™ (bear with me)
XOR, or /Exclusive Or/, is a binary logical operator that is /True/ when only
one of its two operands is /True/. It is usually represented with two symbols: ↮
and ⊕. I prefer ⊕.  Its truth table is:

| A | B | A⊕B |
|---+---+------|
| F | F | F    |
| F | T | T    |
| T | F | T    |
| T | T | F    |

*** The basic interpretation: Or, with exclusion
In its most literal interpretation, XOR can be seen as an extension of OR. While
OR is /True/ when either of its operands is /True/ -or when both are- XOR
excludes this final case.

*** Inequality
XOR, when applied to boolean values, is equivalent to "not equal" ("!=" in
C). XOR is /True/ only when its two operands are different from each other. This
interpretation reveals a profound truth about XOR: it is fundamentally about
difference. XOR answers the question "are these values the same?" rather than
"are these values true?".

*** Toggle/Flip
XORing a boolean value with a constant /True/ inverts the value/truthness of the
value:

A ⊕ /True/ = ¬A

If A is a binary number, this operation flips all the bits of A. We can use this
to flip select bits in a variable, by setting /True/ the corresponding bits in
the second operand.

*** Programmable NOT
NOT is the unary logical operation that inverts the truth value of its
operand. When the input is /True/, the output is /False/, and vice versa. XOR
could be thought of as a version of NOT whose inverting behavior is controllable
by a selector bit. When the second operand is /True/, the output is the negation
of the first operand; When the second operand is /False/, the output remains
equal to the first operand.

*** Addition
One of the most elegant uses of XOR is bridging between logic and arithmetic. If
we take the truth table of XOR and substitute T with 1 and F with 0, we can see
that the XOR operation is equivalent to arithmetic addition (without the
carry). This makes it possible to create an electrical circuit that performs
arithmetic addition on numbers represented in binary. This connection is not
only theoretical: half-adders are circuits in real CPUs and use XOR gates to
compute the sum bit, while the AND gate handles the carry.

*** Reversibility
XOR is its own self-inverse: (a ⊕ b) ⊕ b = a This unique property means XORing
with the same value twice returns you to the original. This is profound because
most operations aren't reversible. This leads directly to some very interesting
applications: encryption (one-time pad), in-place swapping without temporary
variables, error correction codes.
*** Parity/Balance
XOR counts oddness: it returns True when an odd number of inputs are True. For
multiple inputs: a ⊕ b ⊕ c ⊕ d tells you if there's an odd number of True
values. This interpretation is crucial for: parity bits in error detection,
checksums, RAID systems.

*** Wrapping up
So there you have it: the many faces of XOR. I'm sure there are interpretations
of XOR I haven't discovered yet, patterns I haven't recognized. That's part of
what keeps programming interesting: operations and concepts you thought you
understood reveal new depths as you gain experience. What seemed like an
esoteric curiosity when I was learning to program turned out to be a Swiss Army
knife hiding in plain sight. It's an inequality checker, a toggle switch, a
half-adder, and a cryptographic building block all at once. My father gave me a
gift when he introduced me to this strange operator: a gift made of curiosity
and opportunity to be forever mesmerized by all the weird things that are out
there, ready to be discovered.
** mixpost 2026W01 :mixpost:
:PROPERTIES:
:EXPORT_FILE_NAME: 2026-01-01-mixpost-2026W01
:EXPORT_DATE: 2026-01-01T19:01:21+01:00
:END:

1. [[https://www.youtube.com/watch?v=QZkgByta4Kg][Doomwork - Winning The War On Error]]
2. [[https://www.youtube.com/watch?v=jmvCwjzpfuk][Lola Young - Spiders]]
3. [[https://www.youtube.com/watch?v=yf5Yp2WjQ5M][Endeless Dive - Above the Trees]]
4. [[https://www.youtube.com/watch?v=jTv8-DWWW3I][Explosions in the Sky - Moving On]]
5. [[https://www.youtube.com/watch?v=pgCBxvt1I18][AFX - Where's Your Girlfriend?]]

** The People of Emacs are my tribe :emacs:carnival:
:PROPERTIES:
:EXPORT_FILE_NAME: 2025-12-02-emacs-people-are-my-tribe
:EXPORT_DATE: 2025-12-02T21:34:52+01:00
:END:

The People of Emacs are my tribe, even if I never met anyone of them in person.
They are my tribe because I believe that sharing matters, and I feel that they
do too. I've been able to use and enjoy Emacs all these years because of their
generosity, and I hope one day to pay them back.

The People of Emacs have been my tribe since I first watched the video lectures
for [[https://www.youtube.com/playlist?list=PLE18841CABEA24090][MIT 6.001 Structure and Intepretation of Computer Programs]], and what I saw
expressed something I had always felt subconsciously, but had never been able to
articulate: that computer use and computer programming were fundamentally the
same activity; that coding was closer to casting spells than to doing
engineering; and that Lisp was the arcane language of choice for spellbinding
the computer.

The People of Emacs are my tribe because the tool that they have created
reflects many of the principles I hold about software. Some of those priciples
are:

- Software should be free, as in freedom
- Sotware should be programmable, and in the same language it is written in
- [[https://peps.python.org/pep-0020/][Explicit is better than implicit]]
- Plain text always wins in the long term
- [[https://www.cs.yale.edu/homes/perlis-alan/quotes.html][It is better to have 100 functions operate on one data structure than 10 functions on 10 data structures]] (and that data structure is the cons cell)

The People of Emacs are my tribe, and [[https://fosstodon.org/@gosub/115599166682104187][I hope to meet some of them soon]].

This post is my entry for [[https://www.emacswiki.org/emacs/Carnival][Emacs Carnival]] for [[https://curious.port111.com/2025/11/01/emacs-carnival-december-the-people.html][December 2025]].

** Idea: Personal Music Player in a smartwatch form factor :idea:
:PROPERTIES:
:EXPORT_FILE_NAME: 2025-01-03-pmp-smartwatch-formfactor
:EXPORT_DATE: 2025-01-03T16:10:38+01:00
:END:

I wish there was a personal music player in a smartwatch form factor. It would
be a device I could easily take along on a long walk, with uninterrupted music,
free from notifications, and able to display the song title and artist with just
a wrist turn.

Here's what such a device should ideally offer:
- Completely offline functionality
- No smartphone syncing required
- Local storage of at least 64/128 GB, with SD card expandability
- Bluetooth connectivity for headphones or speakers
- A large, low-power screen for easy visibility

** Soldering Musikding "Der Acapulco" overdrive kit :diy:stompbox:der_acapulco:
:PROPERTIES:
:EXPORT_FILE_NAME: 2024-12-30-soldering-der-acapulco
:EXPORT_DATE: 2024-12-30T16:40:07+01:00
:END:

I took advantage of the winter holidays to solder and assemble "[[https://www.musikding.de/The-Acapulco-Overdrive-kit][Der Acapulco]]"
 overdrive pedal kit from [[https://www.musikding.de/][Musikding.de]]. The pedal is a clone of the
"[[https://www.earthquakerdevices.com/acapulco-gold][Acapulco Gold]]" pedal from EarthQuaker Device, which is itself based on the power
section of a vintage Sunn Model T amplifier. The circuit is very simple, it
consists of two LM386 op-amps in series and a single large knob to adjust the
volume.

It was my first soldering experience, and I must say that it was not difficult,
once you acquired a minimum of soldering technique and found the right
combination of solder and soldering iron temperature.

*** General soldering tips

- [[https://www.youtube.com/watch?v=3jAw41LRBxU][This HackMakeMod video]] is the best soldering tutorial I've found online
- I was happy with 0.5mm solder wire, 60/40 lead-tin
- Using the video table I set the soldering iron to 370°C
- The best soldering technique I've found so far is:
  1) touch the tip of the soldering iron to the metal base of the hole and the leg of the component
  2) bring the solder wire close to the point where the three elements touch
  3) let the solder melt for a few seconds (the amount is learned with experience)
  4) remove the solder wire, leave the soldering iron for a few more seconds
  5) after the solder has flowed into the hole, remove the iron

At first I had trouble making clean solder joints with the classic inverted cone
shape, but I was using a solder wire too large, with a melting temperature too
high and I was keeping the soldering iron at a low temperature. Once these three
parameters were adjusted, it was much easier to make soldering joints like those
seen in online tutorials.

*** Specific advice for "Der Acapulco"

In the kit, even if the enclosure is included in the order, there is no knob for
the potentiometer. It must be added separately to the order, otherwise, like me,
you will be forced to order another pedal kit and an extra knob.

Like most guitar pedals, the input jack is on the right and the output jack on
the left. At my first power-on test I thought my pedal didn't work, but I had
only reversed input and output.

The footswitch has no direction, you can only mount it on the daughter board
with the pins aligned horizontally, but you can swap the top with the bottom
with no consequences.

When the instructions say that the LED must have the long pin on the right side,
it means on your right side while looking inside the enclosure. the long pin
must go in the hole on the board indicated with the +.

When soldering capacitors, the positive side is indicated on the board with a +,
while on the capacitors themselves, the negative side is indicated with a light
band, so the light band must be soldered opposite to the +.

Resistors do not have a direction, they can be soldered in both directions, as
well as the ceramic capacitor, the one indicated on the board as C4.
** Random patch generator for Behringer Edge :behringer_edge:
:PROPERTIES:
:EXPORT_FILE_NAME: 2024-12-28-edge-random-patch
:EXPORT_DATE: 2024-12-28T16:33:35+01:00
:END:

Inspired by the [[https://www.youtube.com/watch?v=lbQn_pRpsL8][video from mylarmelodies]] where he discuss with Tom Whitwell
about The Music Thing Workshop System.  In that video Tom says that he created a
random patch generator for the Workshop System, and I wanted to make one for
the synth I have, the Behringer Edge.

#+begin_export html
    <style>
        .pair {
            display: flex;
            align-items: center;
            margin: 15px 0;
        }

        .input, .output {
            height: 30px;
            border-radius: 25px;
            padding: 0 20;
            font-weight: bold;
            line-height: 30px;
            text-align: center;
	    width: 170px;  /* Fixed width for input and output */
        }

        .input {
            border: 2px solid black;
            
        }

        .output {
            background-color: black;
            color: white;
            margin-left: 10px;  /* Space between input and output */
        }

        button {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }
    </style>

    <button onclick="generatePairs()">Generate random patch</button>
    
    <div id="output"></div>

    <script>
        const ins = ["OSC1", "OSC2", "OSC EG", "TRIGGER",
                     "VELOCITY", "PITCH", "VCF EG", "VCA",
                     "VCA EG"];
        const outs = ["OSC1 CV", "OSC2 CV", "OSC DECAY",
                      "ADV/CLOCK", "TRIGGER", "VELOCITY",
                      "NOISE LEVEL", "1-2 FMT AMT", "EXT AUDIO",
                      "TEMPO", "PLAY/STOP", "VCF MOD",
                      "VCF DECAY", "VCA CV", "VCA DECAY"];

        function generatePairs() {
            const n = Math.floor(Math.random() * ins.length) + 1;  // Random number of pairs (between 1 and length of `ins`)
            const randomIns = shuffle([...ins]).slice(0, n);
            const randomOuts = shuffle([...outs]).slice(0, n);

            const outputDiv = document.getElementById('output');
            outputDiv.innerHTML = '';  // Clear previous output

            for (let i = 0; i < n; i++) {
                const pairDiv = document.createElement('div');
                pairDiv.className = 'pair';

                // Create a div for the input with the black curved outline
                const inputDiv = document.createElement('div');
                inputDiv.className = 'input';
                inputDiv.textContent = randomIns[i];

                // Create a div for the output with black background and white text
                const outputDivElement = document.createElement('div');
                outputDivElement.className = 'output';
                outputDivElement.textContent = randomOuts[i];

                // Append both input and output to the pair div
                pairDiv.appendChild(inputDiv);
                pairDiv.appendChild(outputDivElement);

                // Append the pair div to the output div
                outputDiv.appendChild(pairDiv);
            }
        }

        // Shuffle function (Fisher-Yates algorithm)
        function shuffle(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
            return array;
        }
    </script>
#+end_export
* pages
** microlog
:PROPERTIES:
:EXPORT_HUGO_SECTION: /
:EXPORT_FILE_NAME: μlog
:END:
*** Next stop: Topinambur [2015-03-29]
*** Bondage performed with the dishwasher dish rack [2015-03-28]
*** The inextensible nature of the clothesline [2015-03-27]
*** Asparagus straight to the heart [2015-03-21]
*** Moderate consequences [2014-12-04]
*** When you bend over, your philosophy shows itself. [2014-09-29]
*** The Happy Degrow of fingernails [2014-06-14]
*** ADSR. one of these things is not like the others. [2014-06-07]
*** Jimmy Eat World + Strokes = Cloud Nothings [2014-04-06]
*** Genetically Modified Chemtrails [2014-03-29]
*** memorandum of being wasted [2014-03-08]
*** There is a light that sometimes goes out [2014-02-01]
*** Man and Machine, united in vibration [2014-01-20]
*** #OccupyScroogeMcDuckMoneyBin [2014-01-11]
*** Time only sees you if you move. [2014-01-09]
*** rebus sick stantibus [2014-01-04]
*** y parabolas de amor [2014-01-03]
*** Write extravagantly, or the spam filter will descend upon your heads like the judgment of an angry god. [2014-01-01]
*** As if the old world really had an order. [2013-12-29]
*** Instead of staying here, cincillating [2013-12-26]
*** Twitter Error. Terror. [2013-09-29]
*** Empty-handedness [2013-09-28]
*** Being bad at smiling [2013-09-16]
*** A file-changing experience [2013-07-28]
*** Questions, without any mention of frequency of asking. [2013-07-14]
*** To love the internet and hate the web [2013-06-15]
*** Neighborhoods that smell like car air freshener [2013-06-15]
*** He saw his team score a golem [2013-05-08]
*** A contact list that is not changing anymore [2013-04-05]
*** Being in my thirties and they're the wrong size [2013-03-22]
*** From the street, you can see the ceilings of other people's rooms [2013-03-05]
*** The mystery of the existence of rating agencies. [2013-01-17]
*** To fry what no man has ever fried before. [2013-01-16]
*** A world where, what Aaron Swartz did to JSTOR, is neither illegal nor immoral. [2013-01-12]
*** I am tempted by Integralism, which opposes Derivative thinking. [2013-01-05]
*** She was ambiguous and shocking, like the truth table of logical implication. [2013-01-03]
*** music : C Major scale = cooking : x. Solve for x. [2013-01-03]
*** Perhaps, behind every paradox, lies a false dichotomy. [2013-01-03]
*** I have no audience, and I must scream. [2013-01-03]
*** This entry intentionally left blank [2013-01-03]
* refs
- [[https://gohugo.io/documentation/][hugo]]
- [[https://ox-hugo.scripter.co/][ox-hugo]]
- [[https://github.com/monkeyWzr/hugo-theme-cactus][cactus theme]]
* help
** Tangle file from this org
C-c C-v t (org-bable-tangle)
only do it if tangled files are modified
** Babel export all to hugo markdown
C-c C-e H A (org-hugo-export-wim-to-md :all-subtrees)
do it when hugo content is changed
** Rebuild website
M-x compile -> make build
always do it after tangle or babel export
